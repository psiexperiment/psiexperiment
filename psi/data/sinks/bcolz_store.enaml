import logging
log = logging.getLogger(__name__)

import os.path
import atexit
from functools import partial

import bcolz
from atom.api import Atom, Float, Property, Event, Typed, Bool, List, Dict
from enaml.core.api import d_
from enaml.workbench.api import Extension
from enaml.workbench.core.api import Command
import numpy as np
import pandas as pd

from psi.core.enaml.api import PSIManifest
from psi.controller.api import ExperimentAction
from psi.util import declarative_to_dict

from .base_store import BaseStore


class BColzStore(BaseStore):
    '''
    Simple class for storing acquired trial data in hierarchy of bcolz folders.
    '''
    name = 'bcolz_store'

    trial_log = Typed(object)
    event_log = Typed(object)
    continuous_inputs = d_(List())
    epoch_inputs = d_(List())
    _stores = Dict()

    def prepare(self, plugin):
        self._prepare_event_log()
        self._prepare_trial_log(plugin.context_info)
        # TODO: This seems a bit hackish. Do we really need this?
        self._stores['trial_log'] = self.trial_log
        self._stores['event_log'] = self.event_log

    def get_source(self, source_name):
        try:
            return self._stores[source_name]
        except KeyError as e:
            raise AttributeError(source_name)

    def _prepare_trial_log(self, context_info):
        self.trial_log = self._create_trial_log(context_info)

    def _prepare_event_log(self):
        self.event_log = self._create_event_log()

    def process_trials(self, results):
        names = self.trial_log.dtype.names
        columns = []
        for name in names:
            rows = [result[name] for result in results]
            columns.append(rows)
        self.trial_log.append(columns)

    def process_event(self, event, timestamp):
        self.event_log.append([timestamp, event])

    def process_ai_continuous(self, name, data):
        self._stores[name].append(data)

    def process_ai_epochs(self, name, data):
        epochs = []
        metadata = []
        for d in data:
            epochs.append(d['signal'])
            md = d['info']['metadata'].copy()
            md['t0'] = d['info']['t0']
            md['duration'] = d['info']['duration']
            if 'calibration' in md:
                del md['calibration']
            metadata.append(md)

        md_records = pd.DataFrame(metadata).to_records()
        epochs = np.concatenate(epochs, axis=0)
        self._stores[name].append(epochs)
        self._stores[name + '_metadata'].append(md_records)

    def _create_trial_log(self, context_info):
        '''
        Create a table to hold the trial log.
        '''
        filename = self.get_filename('trial_log')
        dtype = [(str(n), i.dtype) for n, i in context_info.items()]
        carray = bcolz.zeros(0, rootdir=filename, mode='w', dtype=dtype)
        atexit.register(carray.flush)
        return carray

    def _create_event_log(self):
        '''
        Create a table to hold the event log.
        '''
        filename = self.get_filename('event_log')
        dtype = [('timestamp', 'float32'), ('event', 'S512')]
        carray = bcolz.zeros(0, rootdir=filename, mode='w', dtype=dtype)
        atexit.register(carray.flush)
        return carray

    def create_ai_continuous(self, name, fs, dtype, **metadata):
        n = int(fs*60*60)
        filename = self.get_filename(name)
        carray = bcolz.carray([], rootdir=filename, mode='w', dtype=dtype,
                              expectedlen=n)
        carray.attrs['fs'] = fs
        for key, value in metadata.items():
            carray.attrs[key] = value
        self._stores[name] = carray
        atexit.register(carray.flush)

    def create_ai_epochs(self, name, fs, epoch_size, dtype, context_items,
                         **metadata):
        # Create signal data store
        n = int(fs*60*60)
        base = self.get_filename(name)
        carray = bcolz.carray([], rootdir=base, mode='w', dtype=dtype,
                              expectedlen=n)
        carray.attrs['fs'] = fs
        for key, value in metadata.items():
            carray.attrs[key] = value

        # Create metadata store
        filename = self.get_filename(name + '_metadata')
        dtype = [(str(n), i.dtype) for n, i in context_items.items()]
        dtype += [('t0', 'float64'), ('duration', 'float64')]
        ctable = bcolz.zeros(0, rootdir=filename, mode='w', dtype=dtype)

        self._stores[name] = carray
        self._stores[name + '_metadata'] = ctable
        atexit.register(carray.flush)
        atexit.register(ctable.flush)

    def finalize(self, workbench):
        # Save the settings file
        cmd = 'psi.save_preferences'
        filename = os.path.join(self.base_path, 'final')
        params = {'filename': filename}
        core = workbench.get_plugin('enaml.workbench.core')
        core.invoke_command(cmd, params)


def prepare(sink, event):
    controller = event.workbench.get_plugin('psi.controller')
    context = event.workbench.get_plugin('psi.context')

    for input_name in sink.epoch_inputs:
        i = controller.get_input(input_name)
        md = declarative_to_dict(i, 'metadata')
        sink.create_ai_epochs(context_items=context.context_items, **md)
        cb = partial(sink.process_ai_epochs, i.name)
        i.add_callback(cb)

    for input_name in sink.continuous_inputs:
        i = controller.get_input(input_name)
        md = declarative_to_dict(i, 'metadata')
        sink.create_ai_continuous(**md)
        cb = partial(sink.process_ai_continuous, i.name)
        i.add_callback(cb)


enamldef BColzStoreManifest(PSIManifest): manifest:

    Extension:
        id = 'commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.id + '.prepare'
            handler = partial(prepare, manifest.contribution)

    Extension:
        id = 'actions'
        point = 'psi.controller.actions'
        ExperimentAction:
            event = 'experiment_prepare'
            command = manifest.id + '.prepare'
