import logging
log =  logging.getLogger(__name__)

import copy
from functools import partial
from collections import defaultdict

import numpy as np

from enaml.core.api import Looper, Include, Conditional
from enaml.workbench.api import Extension
from enaml.workbench.core.api import Command
from enaml.workbench.ui.api import ActionItem, MenuItem, ItemGroup

from psi.context.api import ContextGroup, Parameter
from psi.experiment.api import ItemPreferences, Preferences
from psi.token.primitives import FixedWaveform

from psi.core.enaml.api import PSIManifest
from .experiment_action import ExperimentState, ExperimentEvent, ExperimentAction
from .queue import queues


def toggle_off(event, output):
    output.set_low()


def toggle_on(event, output):
    output.set_high()


def fire(event, output):
    output.fire()


def toggle(event, output):
    if event.parameters['state']:
        toggle_on(event, output)
    else:
        toggle_off(event, output)


def set_token(event, output, output_type):
    if not event.parameters['token']:
        log.warn('No token provided for %s.', output.name)
        return

    output.token = event.parameters['token']

    # TODO: This is a hack. Maybe?
    context_plugin = event.workbench.get_plugin('psi.context')
    context_plugin._refresh_items()


CONTEXT_MAP = {}


def get_parameters(output, block):
    parameters = list(CONTEXT_MAP[output, block].keys())
    for b in block.blocks:
        parameters.extend(get_parameters(output, b))
    return parameters


def load_items(output, block):
    if block is None:
        return []

    from .output import ContinuousOutput
    scope = 'experiment' if isinstance(output, ContinuousOutput) else 'trial'

    block_map = {}
    parameters = []
    for parameter in block.parameters:
        new_parameter = copy.copy(parameter)
        new_parameter.name = '{}_{}_{}' \
            .format(output.name, block.name, parameter.name)
        new_parameter.label = '{} {}' \
            .format(block.label, parameter.label)
        new_parameter.compact_label = '{} {}' \
            .format(block.compact_label, parameter.compact_label)
        new_parameter.group = output.name
        new_parameter.scope = scope
        parameters.append(new_parameter)
        block_map[new_parameter.name] = parameter.name

    CONTEXT_MAP[output, block] = block_map

    for block in block.blocks:
        block_parameters = load_items(output, block)
        parameters.extend(block_parameters)

    return parameters


def initialize_factory(output, block, context):
    input_factories = [initialize_factory(output, b, context) \
                       for b in block.blocks]

    # Pull out list of params accepted by factory class so we can figure out if
    # there's anything important that needs to be added to the context (e.g.,
    # sampling rate).
    code = block.factory.__init__.__code__
    params = code.co_varnames[1:code.co_argcount]

    # Now, pull out the block-specific context.
    block_context = {bn: context[gn] for gn, bn in \
                     CONTEXT_MAP[output, block].items()}

    # TODO: Should this be included when we create the CONTEXT_MAP? 
    if 'fs' in params:
        block_context['fs'] = context['fs']
    if 'calibration' in params:
        block_context['calibration'] = context['calibration']
    if 'input_factory' in params:
        if len(input_factories) != 1:
            raise ValueError('Incorrect number of inputs')
        block_context['input_factory'] = input_factories[0]
    if 'input_factories' in params:
        block_context['input_factories'] = input_factories

    return block.factory(**block_context)


def prepare_output(event, output):
    '''
    Set up the factory in preparation for producing the signal. This allows the
    factory to cache some potentially expensive computations in advance rather
    than just before we actually want the signal played.
    '''
    log.debug('Preparing output %s', output.name)
    core = event.workbench.get_plugin('enaml.workbench.core')
    parameters = {'context_names': get_parameters(output, output.token)}
    context = core.invoke_command('psi.context.get_values', parameters)

    context['fs'] = output.fs
    context['calibration'] = output.calibration

    factory = initialize_factory(output, output.token, context)
    if event.parameters.get('cache', False):
        log.debug('Pregenerating output %s', output.name)
        duration = factory.get_duration()
        samples = round(output.fs*duration)
        waveform = factory.next(samples)
        factory = FixedWaveform(output.fs, waveform)
    output.source = factory


def prepare_output_queue(event, output):
    log.info('Setting up queue for {}'.format(output.name))

    controller = event.workbench.get_plugin('psi.controller')
    context = event.workbench.get_plugin('psi.context')

    action_name = output.name + '_end'
    output.complete_cb = partial(controller.invoke_actions, action_name)

    for setting in context.iter_settings(output.selector_name, 1):
        output.add_setting(setting)


def set_output_queue(event, output):
    queue_class = event.parameters['queue_class']
    output.queue = queue_class()


def prepare_synchronized(synchronized, event):
    log.debug('Preparing synchronized %s', synchronized.name)
    for output in synchronized.outputs:
        prepare_output(event, output)


def start_synchronized(synchronized, event):
    log.debug('Starting synchronized %s', synchronized.name)

    ts = event.parameters['timestamp']
    start = event.parameters.get('start', ts)
    delay = event.parameters.get('delay', 0)

    # Is this a hack? If no timestamp is defined, then assume that the start is
    # 0 (e.g., in the case of experiment_prepare).
    if start is None:
        start = 0

    # For each engine involved in this synchronized output, store a list of the
    # offsets and channel names that need to be updated.
    settings = {e: {'offsets': [], 'channel_names': []} \
                for e in synchronized.engines}

    # First, lock all engines involved to avoid race conditions
    log.debug('Locking all engines')
    for engine in synchronized.engines:
        engine.lock.acquire()

    notify_end = False

    # Activate the outputs
    for output in synchronized.outputs:
        offset = round((start+delay)*output.channel.fs)

        if output.active:
            output.deactivate(offset)
            log.debug('Output %s was active. Deactivating first.', output.name)
            notify_end = True

        if not output.is_ready():
            log.debug('Output %s is not ready.  Preparing.', output.name)
            prepare_output(event, output)

        log.debug('Starting output %s', output.name)
        output.activate(offset)

        setting = settings[output.engine]
        setting['offsets'].append(offset)
        setting['channel_names'].append(output.channel.name)

    # Tell the engines to update the waveform
    for engine, setting in settings.items():
        engine.update_hw_ao_multiple(method='write_position', **setting)

    # Finally, release the lock.
    for engine in synchronized.engines:
        engine.lock.release()

    controller = event.workbench.get_plugin('psi.controller')
    if notify_end:
        controller.invoke_actions('{}_end'.format(synchronized.name),
                                  start+delay)

    controller.invoke_actions('{}_start'.format(synchronized.name),
                              start+delay)


def clear_synchronized(synchronized, event):
    end = event.parameters['timestamp']
    delay = event.parameters.get('delay', 0)

    # For each engine involved in this synchronized output, store a list of the
    # offsets and channel names that need to be updated.
    settings = {e: {'offsets': [], 'channel_names': []} \
                for e in synchronized.engines}

    # First, lock all engines involved to avoid race conditions
    log.debug('Locking all engines')
    for engine in synchronized.engines:
        engine.lock.acquire()

    # Activate the outputs
    for output in synchronized.outputs:
        offset = round((end+delay)*output.channel.fs)

        if output.active:
            output.deactivate(offset)
            log.debug('Deactivating output %s', output.name)

        setting = settings[output.engine]
        setting['offsets'].append(offset)
        setting['channel_names'].append(output.channel.name)

    # Tell the engines to update the waveform
    for engine, setting in settings.items():
        engine.update_hw_ao_multiple(method='write_position', **setting)

    # Finally, release the lock.
    for engine in synchronized.engines:
        engine.lock.release()

    controller = event.workbench.get_plugin('psi.controller')
    controller.invoke_actions('{}_end'.format(synchronized.name),
                              end+delay)


def start_output(event, output):
    ts = event.parameters['timestamp']
    start = event.parameters.get('start', ts)
    delay = event.parameters.get('delay', 0)
    if isinstance(delay, str):
        context = event.workbench.get_plugin('psi.context')
        delay = context.get_value(delay)

    # Is this a hack? If no timestamp is defined, then assume that the start is
    # 0 (e.g., in the case of experiment_prepare).
    if start is None:
        start = 0

    offset = round((start+delay)*output.channel.fs)

    notify_end = False

    try:
        output.engine.lock.acquire()
        buffered_ub = output._buffer.get_samples_ub()
        # Important to lock the engine when activating the output to prevent
        # race conditions
        log.debug('Starting output %s at %d', output.name, offset)
        if output.active:
            output.deactivate(offset)
            log.debug('Output %s was active. Deactivating first.', output.name)
            notify_end = True

        if not output.is_ready():
            log.debug('Output %s is not ready', output.name)
            prepare_output(event, output)

        # This needs to be done before we update the engine since it gets set to
        # None once all samples have been generated.
        duration = output.get_duration()

        output.activate(offset)
        output.engine.update_hw_ao(offset, output.channel.name,
                                   method='write_position')
        output.engine.lock.release()
    except SystemError as e:
        # There wasn't enough time to write the data to the buffer. Need to
        # reset the generator and deactivate the output. The invoking code can
        # then decide what to do about the problem.
        output.deactivate(offset)
        zeros = np.zeros(buffered_ub-offset)
        output._buffer.append_data(zeros)

        output.engine.lock.release()
        log.exception(e)
        log.debug('Invalidated buffer at %d', offset)
    else:
        filter_delay = output.channel.filter_delay
        log.debug('Compensating %s for filter delay %f', output.name,
                  filter_delay)
        controller = event.workbench.get_plugin('psi.controller')
        controller.invoke_actions('{}_start'.format(output.name),
                                  start+delay+filter_delay)
        if duration is not np.inf:
            controller.invoke_actions('{}_end'.format(output.name),
                                      start+delay+duration, delayed=True)

    if notify_end:
        controller.invoke_actions('{}_end'.format(output.name),
                                  start+delay+duration)

def clear_output(event, output):
    end = event.parameters['timestamp']
    delay = event.parameters.get('delay', 0)
    with output.engine.lock:
        log.debug('Clearing output {}'.format(output.name))
        # First, deactivate the output if it's still running
        if not output.active:
            return

        log.debug('Deactivating output {}'.format(output.name))
        output.deactivate()
        # Now, update the channel once the output has been deactivated. This
        # will overwrite any data that contains a fragment of the output
        # waveform.
        offset = round((end+delay)*output.fs)
        output.engine.update_hw_ao(offset, output.channel.name,
                                   method='write_position')

    controller = event.workbench.get_plugin('psi.controller')
    controller.invoke_actions('{}_end'.format(output.name), end+delay)


def decrement_key(event, output):
    counts = defaultdict(int)
    for epoch in event.parameters['data']:
        key = epoch['info']['key']
        counts[key] += 1
    with output.engine.lock:
        for key, count in counts.items():
            try:
                output.queue.decrement_key(key, count)
            except KeyError:
                # This can happen if we are playing epochs so rapidly we gather
                # a few extra before the output queue knows to stop.
                pass


enamldef SynchronizedManifest(PSIManifest): manifest:

    Extension:
        id = 'actions.' + manifest.contribution.name
        point = 'psi.controller.actions'
        ExperimentState:
            name = manifest.contribution.name

    Extension:
        id = 'output_commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.contribution.name + '.prepare'
            handler = partial(prepare_synchronized, manifest.contribution)
        Command:
            id = manifest.contribution.name + '.start'
            handler = partial(start_synchronized, manifest.contribution)
        Command:
            id = manifest.contribution.name + '.clear'
            handler = partial(clear_synchronized, manifest.contribution)


enamldef AnalogOutputManifest(PSIManifest): manifest:

    Extension:
        id = 'output_commands'
        point = 'enaml.workbench.core.commands'
        Conditional:
            condition << manifest.contribution.configurable
            Command:
                id = manifest.contribution.name + '.set_token'
                handler = partial(set_token, output=manifest.contribution,
                                output_type=output_type)
        Command:
            id = manifest.contribution.name + '.prepare'
            handler = partial(prepare_output, output=manifest.contribution)
        Command:
            id = manifest.contribution.name + '.start'
            handler = partial(start_output, output=manifest.contribution)
        Command:
            id = manifest.contribution.name + '.clear'
            handler = partial(clear_output, output=manifest.contribution)

    Conditional:
        condition << manifest.contribution.configurable

        # Create a menu of the tokens available for the output if it's a
        # configurable output.
        Extension:
            id = 'output_menu.' + manifest.contribution.name
            point = 'enaml.workbench.ui.actions'
            MenuItem: menu:
                path = '/equipment/output/{}'.format(manifest.contribution.name)
                label = '{} ({})'.format(manifest.contribution.label, output_type)
                ItemGroup:
                    id = manifest.contribution.name + '_commands'
                ItemGroup:
                    exclusive = True
                    id = manifest.contribution.name + '_tokens'

            Looper:
                # This loops through all tokens available for selection and
                # generates the token menu so we can select the right token. Tokens
                # are an attribute defined in the appropriate manifest subclass (to
                # point to continuous vs epoch-based waveforms).
                iterable << tokens.values()
                ActionItem:
                    path = '{}/{}'.format(menu.path, loop_item.name)
                    label << loop_item.label
                    group = manifest.contribution.name + '_tokens'
                    command = manifest.contribution.name + '.set_token'
                    checked << getattr(manifest.contribution.token, 'name', None) \
                        == loop_item.name
                    checkable = True
                    parameters = {'token': loop_item}
                    enabled << workbench.get_plugin('psi.controller').experiment_state \
                        in ('initialized', 'stopped')

        # Save the selected token and restore it
        Extension:
            id = 'preferences.' +  manifest.contribution.name
            point = 'psi.experiment.preferences'
            rank = 10
            ItemPreferences:
                name = 'output.' + manifest.contribution.name
                item = manifest.contribution

                get_preferences => (workbench):
                    obj = self.get_object(workbench)
                    return {'token_name': obj.token.name}

                set_preferences => (workbench, preferences):
                    # Override the set_preferences since we need to loop into the
                    # token generation machinery. The output does not have access
                    # to this plugin. TODO This is a hack. I'm sure I'll figure out a
                    # better approach eventually.
                    token_plugin = workbench.get_plugin('psi.token')
                    token = token_plugin.get_token(preferences['token_name'])

                    core = workbench.get_plugin('enaml.workbench.core')
                    command = manifest.contribution.name + '.set_token'
                    core.invoke_command(command, parameters={'token': token})

    Extension:
        id = 'items.' + manifest.contribution.name
        point = 'psi.context.items'

        ContextGroup:
            name = manifest.contribution.name
            label = manifest.contribution.label

        Include:
            # list provides an empty list of context items if needed.
            objects << load_items(manifest.contribution,
                                  manifest.contribution.token)

    Extension:
        id = 'actions.' + manifest.contribution.name
        point = 'psi.controller.actions'
        ExperimentState:
            name = manifest.contribution.name
        ExperimentEvent:
            name = manifest.contribution.name + '_failure'


def get_tokens(workbench, ttype):
    try:
        plugin = workbench.get_plugin('psi.token')
        if ttype == 'epoch':
            return plugin._epoch_tokens
        elif ttype == 'continuous':
            return plugin._continuous_tokens
    except ValueError:
        return {}


enamldef EpochOutputManifest(AnalogOutputManifest): manifest:

    attr tokens = get_tokens(workbench, 'epoch')
    attr output_type = 'epoch'


enamldef QueuedEpochOutputManifest(EpochOutputManifest): manifest:

    Extension:
        id = 'commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.contribution.name + '.prepare_queue'
            handler = partial(prepare_output_queue, output=manifest.contribution)
        Command:
            id = manifest.contribution.name + '.set_queue'
            handler = partial(set_output_queue, output=manifest.contribution)
        Command:
            id = manifest.contribution.name + '.decrement_key'
            handler = partial(decrement_key, output=manifest.contribution)


enamldef SelectorQueuedEpochOutputManifest(QueuedEpochOutputManifest): manifest:

    Extension:
        id = 'epoch_output_menu.' + manifest.contribution.name
        point = 'enaml.workbench.ui.actions'
        MenuItem:
            path = '/equipment/output/{}/queue'.format(manifest.contribution.name)
            label = 'ordering'
            ItemGroup:
                exclusive = True
                id = manifest.contribution.name + '.queue'

        Looper:
            iterable << queues.items()

            ActionItem:
                path = '/equipment/output/{}/queue/{}'.format(manifest.contribution.name, loop_item[0])
                label = loop_item[0]
                group = manifest.contribution.name + '.queue'
                checked << isinstance(manifest.contribution.queue, loop_item[1])
                checkable = True
                command = manifest.contribution.name + '.set_queue'
                parameters = {'queue_class': loop_item[1]}
                enabled << workbench.get_plugin('psi.controller').experiment_state \
                    in ('initialized', 'stopped')

    Extension:
        id = 'items'
        point = 'psi.context.items'

        ContextGroup:
            name = manifest.contribution.name + '_sequence'
            label = manifest.contribution.label + ' epoch settings'

            Parameter:
                name = manifest.contribution.name + '_iti_duration'
                label = manifest.contribution.label + ' intertrial interval (s)'
                compact_label = manifest.contribution.label + ' ITI'
                default = 0.1
                scope = 'experiment'

            Parameter:
                name = manifest.contribution.name + '_averages'
                label = manifest.contribution.label + ' averages'
                compact_label = manifest.contribution.label + ' N'
                default = 1
                scope = 'experiment'

    Extension:
        id = 'epoch_output_actions'
        point = 'psi.controller.actions'

        ExperimentAction:
            event = 'experiment_prepare'
            command = manifest.contribution.name + '.prepare_queue'

    Extension:
        id = 'queued_epoch_output_preferences.' +  manifest.contribution.name
        point = 'psi.experiment.preferences'
        rank = 10
        Preferences:
            name = 'queued_epoch_output.' + manifest.contribution.name
            get_preferences => (workbench):
                queue = manifest.contribution.queue
                for name, queue_class in queues.items():
                    if isinstance(queue, queue_class):
                        break
                else:
                    name = None
                return {'queue_type': name}

            set_preferences => (workbench, preferences):
                output = manifest.contribution
                default = 'first-in, first-out'
                if preferences is None:
                    queue_name = default
                elif preferences.get('queue_type') is None:
                    queue_name = default
                else:
                    queue_name = preferences.get('queue_type')
                queue_class = queues[queue_name]
                output.queue = queue_class()


enamldef ContinuousOutputManifest(AnalogOutputManifest): manifest:

    attr tokens = get_tokens(workbench, 'continuous')
    attr output_type = 'continuous'


enamldef ToggleManifest(PSIManifest): manifest:

    Extension:
        id = 'toggle_commands.' + manifest.contribution.name
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.id + '.off'
            handler = partial(toggle_off, output=manifest.contribution)
        Command:
            id = manifest.id + '.on'
            handler = partial(toggle_on, output=manifest.contribution)
        Command:
            id = manifest.id + '.toggle'
            handler = partial(toggle, output=manifest.contribution)

    Extension:
        id = 'toggle_actions.' + manifest.contribution.name
        point = 'enaml.workbench.ui.actions'
        ActionItem:
            path = '/equipment/{}'.format(manifest.contribution.name)
            label = '{}'.format(manifest.contribution.label)
            command = manifest.id + '.toggle'
            parameters << {'state': checked}
            checked << manifest.contribution.state
            checkable = True
            status_tip = command


enamldef TriggerManifest(PSIManifest): manifest:

    Extension:
        id = 'trigger_commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.id + '.trigger'
            handler = partial(fire, output=manifest.contribution)

    Extension:
        id = 'trigger_actions'
        point = 'enaml.workbench.ui.actions'
        ActionItem:
            path = '/equipment/{}'.format(manifest.contribution.name)
            label = '{} trigger'.format(manifest.contribution.label)
            command = manifest.id + '.trigger'
            status_tip = command
