import logging
log =  logging.getLogger(__name__)

import copy
from functools import partial
from collections import ChainMap, Counter

import numpy as np

from enaml.application import deferred_call
from enaml.core.api import Looper, Include, Conditional
from enaml.widgets.api import Action, ToolBar
from enaml.workbench.api import Extension
from enaml.workbench.core.api import Command
from enaml.workbench.ui.api import ActionItem, MenuItem, ItemGroup

from psiaudio.queue import queues

from psi.context.api import ContextGroup, Parameter
from psi.experiment.api import ItemPreferences, Preferences

from psi.core.enaml.api import PSIManifest
from .experiment_action import ExperimentState, ExperimentEvent, ExperimentAction


def set_token(event, output, output_type):
    if not event.parameters['token']:
        log.warn('No token provided for %s.', output.name)
        return

    output.token = event.parameters['token']

    # TODO: This is a hack. Maybe?
    context_plugin = event.workbench.get_plugin('psi.context')
    context_plugin._refresh_items()


CONTEXT_MAP = {}


def get_parameters(output, block):
    parameters = list(CONTEXT_MAP[output, block].keys())
    for b in block.blocks:
        parameters.extend(get_parameters(output, b))
    return parameters


def load_items(output, block):
    if block is None:
        return []

    from .output import ContinuousOutput
    scope = 'experiment' if isinstance(output, ContinuousOutput) else 'trial'

    block_map = {}
    parameters = []
    for parameter in block.parameters:
        new_parameter = copy.copy(parameter)
        new_parameter.name = '{}_{}_{}' \
            .format(output.name, block.name, parameter.name)
        new_parameter.label = '{} {}' \
            .format(block.label, parameter.label)
        new_parameter.compact_label = '{} {}' \
            .format(block.compact_label, parameter.compact_label)
        new_parameter.group_name = output.name
        new_parameter.scope = scope
        parameters.append(new_parameter)
        block_map[new_parameter.name] = parameter.name

    CONTEXT_MAP[output, block] = block_map

    for b in block.blocks:
        b_params = load_items(output, b)
        parameters.extend(b_params)

    return parameters


def generate_waveform(output, context):
    factory = initialize_factory(output, output.token, context)
    return factory.get_samples_remaining()


def initialize_factory(output, block, context):
    input_factories = [initialize_factory(output, b, context) \
                       for b in block.blocks]

    # Pull out list of params accepted by factory class so we can figure out if
    # there's anything important that needs to be added to the context (e.g.,
    # sampling rate).
    code = block.factory.__init__.__code__
    params = code.co_varnames[1:code.co_argcount]

    context = context.copy()
    if 'fs' not in context:
        context['fs'] = output.fs
        context['calibration'] = output.calibration

    # Now, pull out the block-specific context.
    block_context = {bn: context[gn] for gn, bn in \
                     CONTEXT_MAP[output, block].items()}

    # TODO: Should this be included when we create the CONTEXT_MAP? 
    if 'fs' in params:
        block_context['fs'] = context['fs']
    if 'calibration' in params:
        block_context['calibration'] = context['calibration']
    if 'input_factory' in params:
        if len(input_factories) != 1:
            raise ValueError('Incorrect number of inputs')
        block_context['input_factory'] = input_factories[0]
    if 'input_factories' in params:
        block_context['input_factories'] = input_factories

    return block.factory(**block_context)


def prepare_output(event, output):
    '''
    Set up the factory in preparation for producing the signal. This allows the
    factory to cache some potentially expensive computations in advance rather
    than just before we actually want the signal played.
    '''
    log.debug('Preparing output %s', output.name)
    core = event.workbench.get_plugin('enaml.workbench.core')
    parameters = {'context_names': get_parameters(output, output.token)}
    md = core.invoke_command('psi.context.get_values', parameters)

    context = md.copy()
    context['fs'] = output.fs
    context['calibration'] = output.calibration

    factory = initialize_factory(output, output.token, context)
    output.source = factory
    output.source_md = md
    return md


def prepare_output_queue(event, output):
    log.info('Setting up queue for {}'.format(output.name))

    selector_name = event.parameters.get('selector_name', 'default')
    iti_key = event.parameters.get('selector_name', f'{output.name}_iti_duration')
    averages_key = event.parameters.get('selector_name', f'{output.name}_averages')

    controller = event.workbench.get_plugin('psi.controller')
    context = event.workbench.get_plugin('psi.context')
    action_name = output.name + '_end'

    # Link a callback that's invoked in the main thread (to avoid race
    # conditions)
    def cb(event):
        nonlocal controller
        nonlocal action_name
        log.info('Output queue complete. Invoking %s in MainThread',
                  action_name)
        deferred_call(controller.invoke_actions, action_name)
    output.observe('complete', cb)

    for setting in context.iter_settings(selector_name, 1):
        iti_duration = setting[iti_key]
        averages = setting[averages_key]
        output.add_setting(setting, averages=averages, iti_duration=iti_duration)

    controller.invoke_actions(f'{output.name}_queue_ready')


def prepare_synchronized(synchronized, event):
    log.debug('Preparing synchronized %s', synchronized.name)
    for output in synchronized.outputs:
        prepare_output(event, output)


def start_synchronized(synchronized, event):
    try:
        _start_synchronized(synchronized, event)
    except Exception as e:
        log.exception(e)
        controller = event.workbench.get_plugin('psi.controller')
        controller.invoke_actions('{}_failure'.format(synchronized.name))


def _start_synchronized(synchronized, event):
    log.debug('Starting synchronized %s', synchronized.name)
    controller = event.workbench.get_plugin('psi.controller')

    # First, lock all engines involved to avoid race conditions
    for engine in synchronized.engines:
        engine.lock.acquire()
    log.debug('#> Acquired lock for all engines')

    ts = event.parameters['timestamp']
    start = event.parameters.get('start', ts)
    delay = event.parameters.get('delay', 0)
    clear_delay = event.parameters.get('clear_delay', delay)

    # Is this a hack? If no timestamp is defined, then assume that the start is
    # 0 (e.g., in the case of experiment_prepare).
    if start is None:
        start = controller.get_ts()
        log.debug('No starting time provided. Setting start to %f.', start)
    log.debug('Timestamp %r, start %r, delay %r', ts, start, delay)

    if clear_delay > delay:
        raise ValueError('Delay for clearing buffer cannot be greater than delay')

    # For each engine involved in this synchronized output, store a list of the
    # offsets and channel names that need to be updated.
    settings = {e: {'offsets': [], 'names': []} for e in synchronized.engines}
    notify_end = False
    durations = {}

    # Activate the outputs
    for output in synchronized.outputs:
        offset = round((start+delay)*output.channel.fs)
        offset_delay = round((start+clear_delay)*output.channel.fs)

        if output.active:
            output.deactivate(offset_delay)
            log.debug('Output %s was active. Deactivating first.', output.name)
            notify_end = True

        if not output.is_ready():
            log.debug('Output %s is not ready. Preparing.', output.name)
            prepare_output(event, output)

        durations[output.name] = output.get_duration()

        log.debug('Starting output %s', output.name)
        output.activate(offset)

        setting = settings[output.engine]
        setting['offsets'].append(offset_delay)
        setting['names'].append(output.channel.name)

    # Tell the engines to update the waveform
    for engine, setting in settings.items():
        log.debug('%s update %r', engine.name, setting)
        engine.update_hw_ao_multiple(**setting)

    # Finally, release the lock.
    for engine in synchronized.engines:
        engine.lock.release()

    if notify_end:
        controller.invoke_actions('{}_end'.format(synchronized.name), start+clear_delay)

    md = dict(ChainMap(*[o.source_md for o in synchronized.outputs]))
    duration = max(durations.values())
    kw = {
        't0': start+delay,
        'duration': duration,
        'key': None,
        'decrement': None,
        'metadata': md
    }
    controller.invoke_actions('{}_start'.format(synchronized.name), start+delay, kw=kw)
    if duration is not np.inf:
        controller.invoke_actions('{}_end'.format(synchronized.name),
                                  start+delay+duration, delayed=True)


def clear_synchronized(synchronized, event):
    end = event.parameters['timestamp']
    delay = event.parameters.get('delay', 0)

    # For each engine involved in this synchronized output, store a list of the
    # offsets and channel names that need to be updated.
    settings = {e: {'offsets': [], 'names': []} for e in synchronized.engines}

    # First, lock all engines involved to avoid race conditions
    log.debug('Locking all engines')
    for engine in synchronized.engines:
        engine.lock.acquire()

    # Activate the outputs
    for output in synchronized.outputs:
        offset = round((end+delay)*output.channel.fs)

        if output.active:
            output.deactivate(offset)
            log.debug('Deactivating output %s', output.name)

        setting = settings[output.engine]
        setting['offsets'].append(offset)
        setting['names'].append(output.channel.name)

    # Tell the engines to update the waveform
    for engine, setting in settings.items():
        engine.update_hw_ao_multiple(**setting)

    # Finally, release the lock.
    for engine in synchronized.engines:
        engine.lock.release()

    controller = event.workbench.get_plugin('psi.controller')
    controller.invoke_actions('{}_end'.format(synchronized.name),
                              end+delay)


def _get_start_delay(event):
    ts = event.parameters['timestamp']
    start = event.parameters.get('start', ts)
    delay = event.parameters.get('delay', 0)

    if isinstance(delay, str):
        context = event.workbench.get_plugin('psi.context')
        delay = context.get_value(delay)

    # Is this a hack? If no timestamp is defined, then assume that the start is
    # 0 (e.g., in the case of experiment_prepare).
    if start is None:
        start = 0

    return start, delay


def start_output(event, output):
    '''
    clear_delay : The time at which to stop the output if it's currently active.
    '''
    ts = event.parameters['timestamp']
    start = event.parameters.get('start', ts)
    delay = event.parameters.get('delay', 0)
    clear_delay = event.parameters.get('clear_delay', delay)

    if clear_delay > delay:
        raise ValueError('Delay for clearing buffer cannot be greater than delay')

    if isinstance(delay, str):
        context = event.workbench.get_plugin('psi.context')
        delay = context.get_value(delay)

    # Is this a hack? If no timestamp is defined, then assume that the start is
    # 0 (e.g., in the case of experiment_prepare).
    if start is None:
        start = 0

    offset = round((start+delay)*output.channel.fs)
    offset_delay = round((start+clear_delay)*output.channel.fs)
    notify_end = False

    try:
        output.engine.lock.acquire()
        buffered_ub = output._buffer.get_samples_ub()
        # Important to lock the engine when activating the output to prevent
        # race conditions
        log.debug('Starting output %s at %d', output.name, offset)
        if output.active:
            output.deactivate(offset_delay)
            log.debug('Output %s was active. Deactivating first.', output.name)
            notify_end = True
        else:
            update_offset = offset

        if not output.is_ready():
            log.debug('Output %s is not ready', output.name)
            prepare_output(event, output)

        # This needs to be done before we update the engine since it gets set to
        # None once all samples have been generated.
        duration = output.get_duration()

        output.activate(offset_delay)
        output.engine.update_hw_ao(output.channel.name, offset)
        output.engine.lock.release()
    except SystemError as e:
        # There wasn't enough time to write the data to the buffer. Need to
        # reset the generator and deactivate the output. The invoking code can
        # then decide what to do about the problem.
        output.deactivate(offset)
        zeros = np.zeros(buffered_ub-offset)
        output._buffer.append_data(zeros)

        output.engine.lock.release()
        log.exception(e)
        log.debug('Invalidated buffer at %d', offset)
    else:
        filter_delay = output.channel.filter_delay
        log.debug('Compensating %s start event for filter delay %f',
                  output.name, filter_delay)
        controller = event.workbench.get_plugin('psi.controller')

        kw = {'duration': duration, 't0_end': start+delay+duration}
        controller.invoke_actions('{}_start'.format(output.name),
                                  start+delay+filter_delay, kw=kw)
        if duration is not np.inf:
            controller.invoke_actions('{}_end'.format(output.name),
                                      start+delay+duration, delayed=True)

    if notify_end:
        controller.invoke_actions('{}_end'.format(output.name),
                                  start+delay+duration)

def clear_output(event, output):
    end = event.parameters['timestamp']
    delay = event.parameters.get('delay', 0)
    with output.engine.lock:
        log.debug('Clearing output {}'.format(output.name))
        # First, deactivate the output if it's still running
        if not output.active:
            return

        log.debug('Deactivating output {}'.format(output.name))
        output.deactivate()
        # Now, update the channel once the output has been deactivated. This
        # will overwrite any data that contains a fragment of the output
        # waveform.
        offset = round((end+delay)*output.fs)
        output.engine.update_hw_ao(output.channel.name, offset)

    controller = event.workbench.get_plugin('psi.controller')
    controller.invoke_actions('{}_end'.format(output.name), end+delay)


def decrement_key(event, output):
    with output.engine.lock:
        keys = [e.metadata['key'] for e in event.parameters['data']]
        counts = Counter(keys)
        complete_keys = []
        for key, count in counts.items():
            try:
                if output.queue.decrement_key(key, count):
                    complete_keys.append(key)
            except KeyError:
                # This can happen if we are playing epochs so rapidly we gather
                # a few extra before the output queue knows to stop.
                complete_keys.append(key)
    if complete_keys:
        log.debug('Queued keys complete: %r', complete_keys)
        controller = event.workbench.get_plugin('psi.controller')
        controller.invoke_actions(f'{output.name}_keys_complete', keys)


def output_pause(event, output):
    delay = event.parameters.get('delay', 1)
    controller = event.workbench.get_plugin('psi.controller')
    with output.engine.lock:
        time = output.engine.get_ts() + delay
        log.debug('Pausing output %s at %f', output.name, time)
        output.pause(time)
        controller.invoke_actions(output.name + '_paused', time)


def output_resume(event, output):
    delay = event.parameters.get('delay', 1)
    controller = event.workbench.get_plugin('psi.controller')
    with output.engine.lock:
        time = output.engine.get_ts() + delay
        log.debug('Resuming output %s at %f', output.name, time)
        output.resume(time)
        controller.invoke_actions(output.name + '_resumed', time)


enamldef SynchronizedManifest(PSIManifest): manifest:

    Extension:
        id = manifest.id + '.actions'
        point = 'psi.controller.actions'
        ExperimentState:
            name = manifest.contribution.name
        ExperimentEvent:
            name = manifest.contribution.name + '_failure'

    Extension:
        id = manifest.id + '.output_commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.contribution.name + '.prepare'
            handler = partial(prepare_synchronized, manifest.contribution)
        Command:
            id = manifest.contribution.name + '.start'
            handler = partial(start_synchronized, manifest.contribution)
        Command:
            id = manifest.contribution.name + '.clear'
            handler = partial(clear_synchronized, manifest.contribution)


enamldef AnalogOutputManifest(PSIManifest): manifest:

    Extension:
        id = manifest.id + '.output_commands'
        point = 'enaml.workbench.core.commands'
        Conditional:
            condition << manifest.contribution.configurable
            Command:
                id = manifest.contribution.name + '.set_token'
                handler = partial(set_token, output=contribution, output_type=output_type)
        Command:
            id = manifest.contribution.name + '.prepare'
            handler = partial(prepare_output, output=contribution)
        Command:
            id = manifest.contribution.name + '.start'
            handler = partial(start_output, output=contribution)
        Command:
            id = manifest.contribution.name + '.clear'
            handler = partial(clear_output, output=contribution)
        Command:
            id = manifest.contribution.name + '.pause'
            handler = partial(output_pause, output=contribution)
        Command:
            id = manifest.contribution.name + '.resume'
            handler = partial(output_resume, output=contribution)

    Conditional:
        condition << manifest.contribution.configurable

        # Create a menu of the tokens available for the output if it's a
        # configurable output.
        Extension:
            id = manifest.id + '.output_menu'
            point = 'enaml.workbench.ui.actions'
            MenuItem: menu:
                path = '/equipment/output/{}'.format(manifest.contribution.name)
                label = '{} ({})'.format(manifest.contribution.label, output_type)
                ItemGroup:
                    id = manifest.contribution.name + '_commands'
                ItemGroup:
                    exclusive = True
                    id = manifest.contribution.name + '_tokens'

            Looper:
                # This loops through all tokens available for selection and
                # generates the token menu so we can select the right token. Tokens
                # are an attribute defined in the appropriate manifest subclass (to
                # point to continuous vs epoch-based waveforms).
                iterable << tokens.values()
                ActionItem:
                    path = '{}/{}'.format(menu.path, loop_item.name)
                    label << loop_item.label
                    group = manifest.contribution.name + '_tokens'
                    command = manifest.contribution.name + '.set_token'
                    checked << getattr(manifest.contribution.token, 'name', None) \
                        == loop_item.name
                    checkable = True
                    parameters = {'token': loop_item}
                    enabled << workbench.get_plugin('psi.controller').experiment_state \
                        in ('initialized', 'stopped')

        # Save the selected token and restore it
        Extension:
            id = manifest.id + '.preferences'
            point = 'psi.experiment.preferences'
            rank = 10
            ItemPreferences:
                name = 'output.' + manifest.contribution.name
                item = manifest.contribution

                get_preferences => (workbench):
                    obj = self.get_object(workbench)
                    return {'token_name': obj.token.name}

                set_preferences => (workbench, preferences):
                    # Override the set_preferences since we need to loop into the
                    # token generation machinery. The output does not have access
                    # to this plugin. TODO This is a hack. I'm sure I'll figure out a
                    # better approach eventually.
                    token_plugin = workbench.get_plugin('psi.token')
                    token = token_plugin.get_token(preferences['token_name'])

                    core = workbench.get_plugin('enaml.workbench.core')
                    command = manifest.contribution.name + '.set_token'
                    core.invoke_command(command, parameters={'token': token})

    Extension:
        id = manifest.id + '.items'
        point = 'psi.context.items'

        ContextGroup:
            name = manifest.contribution.name
            label = manifest.contribution.label

        Include:
            # list provides an empty list of context items if needed.
            objects << load_items(manifest.contribution,
                                  manifest.contribution.token)

    Extension:
        id = manifest.id + '.actions'
        point = 'psi.controller.actions'
        ExperimentState:
            name = manifest.contribution.name
        ExperimentEvent:
            name = manifest.contribution.name + '_failure'
        ExperimentEvent:
            name = manifest.contribution.name + '_paused'
        ExperimentEvent:
            name = manifest.contribution.name + '_resumed'


def get_tokens(workbench, ttype):
    try:
        plugin = workbench.get_plugin('psi.token')
        if ttype == 'epoch':
            return plugin._epoch_tokens
        elif ttype == 'continuous':
            return plugin._continuous_tokens
    except ValueError:
        return {}


enamldef EpochOutputManifest(AnalogOutputManifest): manifest:

    attr tokens = get_tokens(workbench, 'epoch')
    attr output_type = 'epoch'


def get_pause_text(contribution, is_paused):
    base = 'Resume' if is_paused else 'Pause'
    return '{} {}'.format(base, contribution.name)


enamldef QueuedEpochOutputManifest(EpochOutputManifest): manifest:

    attr id_extra = '.queued_epoch_output'

    Extension:
        id = manifest.id + id_extra + '.commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.contribution.name + '.prepare_queue'
            handler = partial(prepare_output_queue, output=contribution)
        Command:
            id = manifest.contribution.name + '.decrement_key'
            handler = partial(decrement_key, output=contribution)

    Extension:
        id = manifest.id + id_extra + '.actions'
        point = 'psi.controller.actions'

        ExperimentEvent:
            name = f'{manifest.contribution.name}_queue_ready'

        ExperimentEvent:
            name = f'{manifest.contribution.name}_keys_complete'

    # Uses unicode symbols as icons for sake of simplicity.
    Extension:
        id = manifest.id + '.toolbar'
        point = 'psi.experiment.toolbar'

        ToolBar:
            Action:
                checkable = True
                text << get_pause_text(manifest.contribution,
                                       manifest.contribution.paused)
                enabled << controller.experiment_state == 'running'
                triggered ::
                    core = workbench.get_plugin('enaml.workbench.core')
                    cmd = '.pause' if checked else '.resume'
                    core.invoke_command(manifest.contribution.name + cmd)


enamldef SelectorQueuedEpochOutputManifest(QueuedEpochOutputManifest): manifest:

    Extension:
        id = manifest.id + '.epoch_output_actions'
        point = 'psi.controller.actions'

        ExperimentAction:
            event = 'engines_configured'
            command = manifest.contribution.name + '.prepare_queue'


enamldef ContinuousOutputManifest(AnalogOutputManifest): manifest:

    attr tokens = get_tokens(workbench, 'continuous')
    attr output_type = 'continuous'


def subscribe_to_queue(event, output):
    controller = event.workbench.get_plugin('psi.controller')
    event_added = f'{output.name}_added'
    event_removed = f'{output.name}_removed'

    def stim_added(info):
        nonlocal controller
        nonlocal event_added
        info = info.copy()
        t0 = info.pop('t0')
        controller.invoke_actions(event_added, t0, kw=info)

    def stim_removed(info):
        nonlocal controller
        nonlocal event_removed
        info = info.copy()
        t0 = info.pop('t0')
        controller.invoke_actions(event_removed, t0, kw=info)

    output.connect(stim_added, 'added')
    output.connect(stim_removed, 'removed')


enamldef ContinuousQueuedOutputManifest(ContinuousOutputManifest): manifest:

    Extension:
        id = manifest.id + '.continuous_queued_output_commands'
        point = 'enaml.workbench.core.commands'

        Command:
            id = manifest.contribution.name + '.subscribe_to_queue'
            handler = partial(subscribe_to_queue,
                              output=manifest.contribution)

    Extension:
        id = manifest.id + '.continuous_queued_output_actions'
        point = 'psi.controller.actions'

        ExperimentAction:
            event = 'engines_configured'
            command = manifest.contribution.name + '.subscribe_to_queue'
            weight = 0


################################################################################
# TimedTriggerManifest
################################################################################
enamldef TimedTriggerManifest(PSIManifest): manifest:

    Extension:
        id = manifest.id + '.timed_digital_output_commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.contribution.name + '.trigger'
            handler = lambda e: manifest.contribution.trigger(
                e.parameters['timestamp'],
                e.parameters['duration'],
            )



################################################################################
# ToggleManifest
################################################################################
def toggle_off(event, output):
    output.set_low()


def toggle_on(event, output):
    output.set_high()


def toggle(event, output):
    if event.parameters['state']:
        toggle_on(event, output)
    else:
        toggle_off(event, output)


enamldef ToggleManifest(PSIManifest): manifest:

    Extension:
        id = manifest.id + '.toggle_commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = manifest.contribution.name + '.off'
            handler = partial(toggle_off, output=manifest.contribution)
        Command:
            id = manifest.contribution.name + '.on'
            handler = partial(toggle_on, output=manifest.contribution)
        Command:
            id = manifest.contribution.name + '.toggle'
            handler = partial(toggle, output=manifest.contribution)

    Extension:
        id = manifest.id + '.toggle_actions'
        point = 'enaml.workbench.ui.actions'
        ActionItem:
            path = '/equipment/{}'.format(manifest.contribution.name)
            label = '{}'.format(manifest.contribution.label)
            command = manifest.contribution.name + '.toggle'
            parameters << {'state': checked}
            checked << manifest.contribution.state
            checkable = True
            status_tip = command


################################################################################
# TriggerManifest
################################################################################
enamldef TriggerManifest(PSIManifest): manifest:

    Extension:
        id = manifest.id + '.trigger_commands'
        point = 'enaml.workbench.core.commands'
        Command:
            id = f'{manifest.contribution.name}.fire'
            handler = lambda e: \
                manifest.contribution.fire(e.parameters.get('duration'))
